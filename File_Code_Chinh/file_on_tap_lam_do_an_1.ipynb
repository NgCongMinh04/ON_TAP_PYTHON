{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# các kiến thức sẽ được ôn \n",
    "# Thư viện Lần 1 : \n",
    "import pandas as pd \n",
    "import re \n",
    "import datetime\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "from urllib.request import urlopen # là thư viện dùng để xữ lí url "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lấy mã HTML và CSS : \n",
    "# Cách 1 :  Dùng với thư viện url và bs4 \n",
    "#html = urlopen('http://pythonscraping.com/pages/page1.html')\n",
    "#print(html.read())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# thao tác với cách 1 : \n",
    "\n",
    "# cách lấy dữ liệu với cấu trúc HTML \n",
    "# yêu cầu phải có hai thư viện BS4 và URL\n",
    "#html = urlopen('http://www.pythonscraping.com/pages/page1.html')\n",
    "#bs = BeautifulSoup(html.read(), 'html.parser')\n",
    "#print(bs.h1)\n",
    "\n",
    "# tìm dữ liệu bằng class \n",
    "# .find_all(attrs={'class': ['mw-ui-icon-wikimedia-listBullet', 'vector-icon']})\n",
    "\n",
    "# Kiểm thử file có mở được hay không qua hai thư viện con và lệnh try , except \n",
    "from urllib.error import HTTPError\n",
    "from urllib.error import URLError\n",
    "\n",
    "#try:\n",
    "#    html = urlopen('https://pythonscrapingthisurldoesnotexist.com')\n",
    "#except HTTPError as e :\n",
    "#    print(\"The server returned an HTTP error\")\n",
    "#except URLError as e : \n",
    "#    print(\"The server could not be found!\")\n",
    "#else: \n",
    "#    print(html.read())\n",
    "\n",
    "#Kiểm thử kết hợp với bs4 \n",
    "\n",
    "#def getTitle(url):\n",
    "#    try:\n",
    "#       html = urlopen(url)\n",
    "#    except HTTPError as e:\n",
    "#        return None\n",
    "#    try:\n",
    "#        bsObj = BeautifulSoup(html.read(), \"lxml\") \n",
    "#           lmxl giống với html.parser nhưng lmxl nhanh hơn nhớ tải thư viện lmxl \n",
    "#        title = bsObj.body.h1\n",
    "#    except AttributeError as e: \n",
    "#        return None\n",
    "#    return title\n",
    "\n",
    "#title = getTitle(\"http://www.pythonscraping.com/pages/page1.html\")\n",
    "#if title == None:\n",
    "#    print(\"Title could not be found\")\n",
    "#else:\n",
    "#    print(title)\n",
    "\n",
    "# Xử lí với file có màu sắc \n",
    "# dùng findAll\n",
    "#.find_all('span', {'class':{'green', 'red'}})\n",
    "#name = bs.findAll('span', {'class' : ['green','red']})\n",
    "#for b1 in name :\n",
    "#    print(b1.get_text())\n",
    "# tóm gọn : \n",
    "#allText = bs.find_all('span', {'class':{'green', 'red'}})\n",
    "#print([text for text in allText])\n",
    "\n",
    "# Cách dùng \n",
    "# bs.find_all(lambda tag: tag.get_text() == 'Or maybe he\\'s only resting?')\n",
    "# bs.find_all('', text='Or maybe he\\'s only resting?')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# thư viện lần 2 : \n",
    "import random"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
